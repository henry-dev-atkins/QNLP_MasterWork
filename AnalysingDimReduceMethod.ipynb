{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_to_rotations(symbols):\n",
    "    noun_parameters, subject_parameters = get_word_dims_from_ansatz(ANSATZ)\n",
    "\n",
    "    weights = np.zeros(shape=(len(symbols)))\n",
    "    for i, word_symbol in enumerate(symbols):\n",
    "        word_string, word_dims, word_index = retrive_word_param_from_symbols(word_symbol, noun_parameters, subject_parameters)\n",
    "        weights[i] = word_vector_dict[word_string]['pca_'+str(word_dims)][word_index]/(2*np.pi)\n",
    "    return weights\n",
    "\n",
    "def normal_distribution_to_rotations(symbols):\n",
    "    noun_parameters, subject_parameters = get_word_dims_from_ansatz(ANSATZ)\n",
    "\n",
    "    weights = np.zeros(shape=(len(symbols)))\n",
    "    for i, word_symbol in enumerate(symbols):\n",
    "        word_string, word_dims, word_index = retrive_word_param_from_symbols(word_symbol, noun_parameters, subject_parameters)\n",
    "        \n",
    "        mean_of_word = word_vector_dict[word_string][384].mean()\n",
    "        std_of_word = word_vector_dict[word_string][384].std()\n",
    "        s = np.random.normal(mean_of_word, std_of_word, 1)\n",
    "\n",
    "        weights[i] = s\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_train_model(diagrams, train_dataset, val_dataset, model_type, noun_count, ansatz, sentence_count, asnatz_hyperparams, ansatz_name, loss_name, optimizer_name, optimizer_hyperparams_str, num_epochs, batch_size, seed):\n",
    "    if model_type == 'random':\n",
    "        model = NumpyModel.from_diagrams(diagrams, use_jit=True)\n",
    "    elif model_type == 'pca':\n",
    "        model = EncodedNumpyModel.from_diagrams(diagrams, use_jit=True)\n",
    "        model.type_of_encoding = 'pca'\n",
    "        #model.param_initialise_method = pca_to_rotations\n",
    "        model.initialise_weights()\n",
    "    elif model_type == 'normal':\n",
    "        model = EncodedNumpyModel.from_diagrams(diagrams, use_jit=True)\n",
    "        #model.param_initialise_method = normal_distribution_to_rotations\n",
    "        model.initialise_weights()\n",
    "    elif model_type == 'uniform_zero':\n",
    "        model = EncodedNumpyModel.from_diagrams(diagrams, use_jit=True)\n",
    "        #model.param_initialise_method = normal_distribution_to_rotations\n",
    "        model.initialise_weights()\n",
    "    elif model_type == 'uniform_half':\n",
    "        model = EncodedNumpyModel.from_diagrams(diagrams, use_jit=True)\n",
    "        #model.param_initialise_method = normal_distribution_to_rotations\n",
    "        model.initialise_weights()\n",
    "    elif model_type == 'uniform_one':\n",
    "        model = EncodedNumpyModel.from_diagrams(diagrams, use_jit=True)\n",
    "        #model.param_initialise_method = normal_distribution_to_rotations\n",
    "        model.initialise_weights()\n",
    "    elif model_type == 'svd':\n",
    "        model = EncodedNumpyModel.from_diagrams(diagrams, use_jit=True)\n",
    "        #model.param_initialise_method = normal_distribution_to_rotations\n",
    "        model.initialise_weights()\n",
    "    elif model_type == 'normal_around_half':\n",
    "        model = EncodedNumpyModel.from_diagrams(diagrams, use_jit=True)\n",
    "        #model.param_initialise_method = normal_around_half_distribution_to_rotations\n",
    "        model.initialise_weights()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid ansatz: {ansatz_name}\")\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
