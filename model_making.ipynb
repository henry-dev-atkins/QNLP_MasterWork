{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from discopy.grammar import Word\n",
    "from discopy.rigid import Cup, Id, Ty\n",
    "import torch\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from lambeq import LossFunction, PennyLaneModel, PytorchTrainer, QuantumTrainer, SPSAOptimizer, NumpyModel, MSELoss, Dataset, AtomicType, IQPAnsatz, Sim14Ansatz, Sim15Ansatz, StronglyEntanglingAnsatz, BobcatParser\n",
    "from lambeq.pregroups import remove_cups\n",
    "import jax as jnp\n",
    "\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_data():\n",
    "    df = pd.read_csv('Data/LargerSadrKartTransative.txt', sep=' ')\n",
    "    # assign column names to the dataframe\n",
    "    df.columns = ['annotator', 'subject1', 'verb1', 'object1', 'subject2', 'verb2', 'object2', 'score']\n",
    "    # group the data by the three sentence columns and calculate the mean and standard deviation of the score column\n",
    "    grouped_data = df.groupby(['subject1', 'verb1', 'object1', 'subject2', 'verb2', 'object2']).agg({'score': [np.mean, np.std]}).reset_index()\n",
    "    # flatten the multi-level column names of the grouped data\n",
    "    grouped_data.columns = [' '.join(col).strip() for col in grouped_data.columns.values]\n",
    "    # rename the mean and std columns to 'score' and 'range' respectively\n",
    "    grouped_data.rename(columns={'score mean': 'score', 'score std': 'range'}, inplace=True)\n",
    "    grouped_data['score'] = grouped_data['score']/grouped_data['score'].max()\n",
    "    unique_word_list = []\n",
    "    for ind, row in grouped_data.iterrows():\n",
    "        for i in [row['subject1'],row['verb1'],row['object1'], row['subject2'],row['verb2'],row['object2']]:\n",
    "            unique_word_list.append(i)\n",
    "    unique_word_list = list(set(unique_word_list)) #Makes word_list from word_list's unique elements\n",
    "    grouped_data.to_csv(\"Data/AveragedLargerSadrKartTransative.txt\")\n",
    "    # Create an instance of MinMaxScaler\n",
    "    #ERROR: SCALING STOPPED ALL CONVERGENCES!\n",
    "    #scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    # Rescale the 'score' column\n",
    "    #grouped_data['score'] = scaler.fit_transform(grouped_data[['score']])\n",
    "    return grouped_data, unique_word_list\n",
    "dataset, unique_word_list = read_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_nth_rows_sentences(data, row1, row2=None):\n",
    "    if not row2:\n",
    "        row2=row1\n",
    "    sentence1 = data['subject'+str(1)][row1] + \" \" + data['verb'+str(1)][row1]  + \" \" + data['object'+str(1)][row1] \n",
    "    sentence2 = data['subject'+str(2)][row2] + \" \" + data['verb'+str(2)][row2]  + \" \" + data['object'+str(2)][row2] \n",
    "    return sentence1, sentence2\n",
    "\n",
    "def make_sentence_a_state(sentence):\n",
    "    diagram = diagram_to_sentence(sentence.split(\" \"))\n",
    "    diagram = remove_cups(diagram)\n",
    "    return diagram\n",
    "\n",
    "def make_diagram_a_circuit(diagram, ansatz, dagger=False):\n",
    "    discopy_circuit = ansatz(diagram)\n",
    "    if dagger:\n",
    "        discopy_circuit = discopy_circuit.dagger()\n",
    "    return discopy_circuit\n",
    "\n",
    "def concat_circuits_into_inner_product(circuit1, circuit2):\n",
    "    concat_circuit = circuit1 >> circuit2\n",
    "    return concat_circuit\n",
    "\n",
    "def make_diagrams(data, sentence1, sentence2=None):\n",
    "    if type(sentence1) == int:\n",
    "        sentence1, sentence2 = retrive_nth_rows_sentences(data, sentence1, sentence2)\n",
    "    diagram1 = make_sentence_a_state(sentence1)\n",
    "    diagram2 = make_sentence_a_state(sentence2)\n",
    "    return diagram1, diagram2\n",
    "\n",
    "def diagram_to_sentence(word_list):\n",
    "    n, s = Ty('n'), Ty('s')\n",
    "    words = [\n",
    "        Word(word_list[0], n),\n",
    "        Word(word_list[1], n.r @ s @ n.l),\n",
    "        Word(word_list[2], n)\n",
    "    ]\n",
    "    cups = Cup(n, n.r) @ Id(s) @ Cup(n.l, n)\n",
    "    assert Id().tensor(*words) == words[0] @ words[1] @ words[2]\n",
    "    assert Ty().tensor(*[n.r, s, n.l]) == n.r @ s @ n.l\n",
    "    diagram = Id().tensor(*words) >> cups\n",
    "    return diagram\n",
    "\n",
    "def get_word_dims_from_ansatz(ANSATZ):\n",
    "    noun = ANSATZ.ob_map[Ty('n')]\n",
    "    sent = ANSATZ.ob_map[Ty('s')]\n",
    "    if isinstance(ANSATZ, IQPAnsatz):\n",
    "        noun_parameters = 3 if noun == 1 else (noun-1)\n",
    "        subject_parameters = noun + noun + sent - 1\n",
    "        return noun_parameters, subject_parameters\n",
    "    if isinstance(ANSATZ, Sim14Ansatz):\n",
    "        noun_parameters = 3 if noun == 1 else noun*4\n",
    "        subject_parameters = 4*(noun + noun + sent)\n",
    "        return noun_parameters, subject_parameters\n",
    "    if isinstance(ANSATZ, Sim15Ansatz):\n",
    "        noun_parameters = 3 if noun == 1 else noun*2\n",
    "        subject_parameters = 2*(noun + noun + sent)\n",
    "        return noun_parameters, subject_parameters\n",
    "    if isinstance(ANSATZ, StronglyEntanglingAnsatz):\n",
    "        print(\"ERROR NOT IMPLEMENTED YET\")\n",
    "        pass\n",
    "\n",
    "def make_circuit_from_diagrams(diagram1, diagram2, ansatz, drawing=False):\n",
    "    discopy_circuit1 = make_diagram_a_circuit(diagram1, ansatz)\n",
    "    discopy_circuit2 = make_diagram_a_circuit(diagram2, ansatz, dagger=True)\n",
    "    discopy_circuit = concat_circuits_into_inner_product(discopy_circuit1, discopy_circuit2)\n",
    "\n",
    "    if drawing:\n",
    "        discopy_circuit1.draw(figsize=(5, 5))\n",
    "        discopy_circuit2.draw(figsize=(5, 5))\n",
    "        discopy_circuit.draw(figsize=(5, 10))   \n",
    "\n",
    "    pennylane_circuit = discopy_circuit.to_pennylane()\n",
    "    return pennylane_circuit, discopy_circuit\n",
    "\n",
    "def make_circuit_from_df_row(data, row_number, ansatz):\n",
    "    diagram1, diagram2 = make_diagrams(data, row_number)\n",
    "    qml_circuit, discopy_circuit = make_circuit_from_diagrams(diagram1, diagram2, ansatz, False)\n",
    "    return qml_circuit, discopy_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(ansatz, seed, batch_size):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    labels = dataset['score']\n",
    "\n",
    "    training = pd.read_csv(\"Data/TrainingData.txt\")\n",
    "    test = pd.read_csv(\"Data/TestData.txt\")\n",
    "\n",
    "    train_data =  [make_circuit_from_df_row(training, i, ansatz)[1] for i in range(len(training))]\n",
    "    train_labels = labels[training['Unnamed: 0'].values]\n",
    "    val_data = [make_circuit_from_df_row(test, i, ansatz)[1] for i in range(len(test))] \n",
    "    val_labels = labels[test['Unnamed: 0'].values]\n",
    "\n",
    "    diagrams = train_data + val_data\n",
    "\n",
    "    train_dataset = Dataset(train_data,train_labels,batch_size=batch_size)\n",
    "    val_dataset = Dataset(val_data, val_labels, batch_size=batch_size)\n",
    "    return diagrams, train_dataset, val_dataset\n",
    "\n",
    "class EncodedNumpyModel(NumpyModel):\n",
    "     def initialise_weights(self) -> None:\n",
    "        if not self.symbols:\n",
    "            raise ValueError('Symbols not initialised. Instantiate through '\n",
    "                            '`from_diagrams()`.')\n",
    "        self.weights = self.param_initialise_method(self.symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_exists_and_load(model_folder_path):\n",
    "    if os.path.exists(model_folder_path):\n",
    "        # If the model folder already exists, load the information from the files and return\n",
    "        model_params_filepath = os.path.join(model_folder_path, \"model_params.joblib\")\n",
    "        training_losses_filepath = os.path.join(model_folder_path, \"training_losses.npy\")\n",
    "        validation_losses_filepath = os.path.join(model_folder_path, \"validation_losses.npy\")\n",
    "\n",
    "        model_params = joblib.load(model_params_filepath)\n",
    "        training_losses = np.load(training_losses_filepath)\n",
    "        validation_losses = np.load(validation_losses_filepath)\n",
    "\n",
    "        return model_params, training_losses, validation_losses, True\n",
    "    return None, None, None, False\n",
    "\n",
    "def save_model_training(model_folder_path, model_params, training_losses, validation_losses):\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "\n",
    "    model_params_filepath = os.path.join(model_folder_path, \"model_params.joblib\")\n",
    "    training_losses_filepath = os.path.join(model_folder_path, \"training_losses.npy\")\n",
    "    validation_losses_filepath = os.path.join(model_folder_path, \"validation_losses.npy\")\n",
    "\n",
    "    joblib.dump(model_params, model_params_filepath)\n",
    "    np.save(training_losses_filepath, training_losses)\n",
    "    np.save(validation_losses_filepath, validation_losses)\n",
    "    return\n",
    "\n",
    "def run_quantum_trainer(model_type, ansatz, loss_function, optimizer, optim_hyperparams, num_epochs, batch_size, seed, text='text'):\n",
    "    ### Preperation ###\n",
    "    noun_count = ansatz.ob_map[Ty('n')]\n",
    "    sentence_count = ansatz.ob_map[Ty('s')]\n",
    "    asnatz_hyperparams = {'n':noun_count, 's':sentence_count, 'layers':ansatz.n_layers}\n",
    "    \n",
    "    \n",
    "    ansatz_name = ansatz.__class__.__name__.lower()\n",
    "    loss_name = loss_function.__class__.__name__.lower()\n",
    "    optimizer_name = optimizer.__name__.lower()\n",
    "    optimizer_hyperparams_str = '_'.join([f\"{key}{val}\" for key, val in optim_hyperparams.items()])\n",
    "    asnatz_hyperparams_str = '_'.join([f\"{key}{val}\" for key, val in asnatz_hyperparams.items()])\n",
    "\n",
    "    model_folder = f\"{model_type}_{ansatz_name}_{asnatz_hyperparams_str}_{loss_name}_{optimizer_name}_{optimizer_hyperparams_str}_epochs{num_epochs}_batch{batch_size}_seed{seed}\"\n",
    "    model_folder_path = os.path.join(\"models\", model_folder)\n",
    "\n",
    "    model_params, training_losses, validation_losses, dont_proceed_if_model_exists = check_model_exists_and_load(model_folder_path)\n",
    "    if dont_proceed_if_model_exists is True:\n",
    "        return model_params, training_losses, validation_losses\n",
    "    print(ansatz_name, asnatz_hyperparams_str, ansatz.n_layers, loss_name, optimizer_name, optimizer_hyperparams_str, num_epochs, batch_size, seed)\n",
    "    \n",
    "    ### Data Produced\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    diagrams, train_dataset, val_dataset = get_datasets(ansatz, seed, batch_size)\n",
    "    \n",
    "    ### Model Assignment according to function inputs\n",
    "    if model_type == 'random':\n",
    "        model = NumpyModel.from_diagrams(diagrams, use_jit=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid ansatz: {ansatz_name}\")\n",
    "\n",
    "    trainer = QuantumTrainer(\n",
    "        model,\n",
    "        loss_function=loss_function,\n",
    "        epochs=num_epochs,\n",
    "        optimizer=optimizer,\n",
    "        optim_hyperparams=optim_hyperparams,\n",
    "        evaluate_on_train=True,\n",
    "        verbose=text,\n",
    "        seed=seed\n",
    "    )\n",
    "    trainer.fit(train_dataset, val_dataset, logging_step=500)\n",
    "\n",
    "    save_model_training(model_folder_path, model.weights, trainer.train_epoch_costs, trainer.val_costs)\n",
    "\n",
    "    return model_params, training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim14ansatz n1_s1_layers2 2 mseloss spsaoptimizer a0.01_c1.0_A5.0 500 2 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\discopy\\messages.py:95: UserWarning: Since discopy v0.4.3 the behaviour of permutation has changed. Pass inverse=False to get the default behaviour.\n",
      "  warnings.warn(message)\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "Epoch 1:    train/loss: 0.1915   valid/loss: 0.1276\n",
      "Epoch 500:  train/loss: 0.1893   valid/loss: 0.1276\n",
      "\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim14ansatz n1_s1_layers2 2 mseloss spsaoptimizer a1.0_c0.01_A5.0 500 2 42\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m optimizer_name, optimizer \u001b[39min\u001b[39;00m optimizer_config\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     49\u001b[0m     \u001b[39mfor\u001b[39;00m o_param_name, o_param \u001b[39min\u001b[39;00m optimizer_param_config\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 50\u001b[0m         run_quantum_trainer(\u001b[39m'\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m'\u001b[39;49m, ansatz(ansatz_param, n_layers \u001b[39m=\u001b[39;49m layer), loss_function, optimizer, o_param, EPOCHS, BATCH_SIZE, SEED, \u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[5], line 70\u001b[0m, in \u001b[0;36mrun_quantum_trainer\u001b[1;34m(model_type, ansatz, loss_function, optimizer, optim_hyperparams, num_epochs, batch_size, seed, text)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid ansatz: \u001b[39m\u001b[39m{\u001b[39;00mansatz_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m trainer \u001b[39m=\u001b[39m QuantumTrainer(\n\u001b[0;32m     61\u001b[0m     model,\n\u001b[0;32m     62\u001b[0m     loss_function\u001b[39m=\u001b[39mloss_function,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     seed\u001b[39m=\u001b[39mseed\n\u001b[0;32m     69\u001b[0m )\n\u001b[1;32m---> 70\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(train_dataset, val_dataset, logging_step\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n\u001b[0;32m     72\u001b[0m save_model_training(model_folder_path, model\u001b[39m.\u001b[39mweights, trainer\u001b[39m.\u001b[39mtrain_epoch_costs, trainer\u001b[39m.\u001b[39mval_costs)\n\u001b[0;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m model_params, training_losses, validation_losses\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\lambeq\\training\\quantum_trainer.py:199\u001b[0m, in \u001b[0;36mQuantumTrainer.fit\u001b[1;34m(self, train_dataset, val_dataset, evaluation_step, logging_step)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    192\u001b[0m         train_dataset: Dataset,\n\u001b[0;32m    193\u001b[0m         val_dataset: Dataset \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    194\u001b[0m         evaluation_step: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m    195\u001b[0m         logging_step: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m_training \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(train_dataset, val_dataset, evaluation_step, logging_step)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m_training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\lambeq\\training\\trainer.py:428\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, train_dataset, val_dataset, evaluation_step, logging_step)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[39mfor\u001b[39;00m v_batch \u001b[39min\u001b[39;00m tqdm(val_dataset,\n\u001b[0;32m    422\u001b[0m                     desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation batch\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    423\u001b[0m                     total\u001b[39m=\u001b[39mbatches_per_validation,\n\u001b[0;32m    424\u001b[0m                     disable\u001b[39m=\u001b[39mdisable_tqdm,\n\u001b[0;32m    425\u001b[0m                     leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m                     position\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[0;32m    427\u001b[0m     x_val, y_label_val \u001b[39m=\u001b[39m v_batch\n\u001b[1;32m--> 428\u001b[0m     y_hat_val, cur_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidation_step(v_batch)\n\u001b[0;32m    429\u001b[0m     val_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m cur_loss \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(x_val)\n\u001b[0;32m    430\u001b[0m     seen_so_far \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x_val)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\lambeq\\training\\quantum_trainer.py:187\u001b[0m, in \u001b[0;36mQuantumTrainer.validation_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Perform a validation step.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \n\u001b[0;32m    175\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    186\u001b[0m x, y \u001b[39m=\u001b[39m batch\n\u001b[1;32m--> 187\u001b[0m y_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[0;32m    188\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function(y_hat, y)\n\u001b[0;32m    189\u001b[0m \u001b[39mreturn\u001b[39;00m y_hat, loss\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\lambeq\\training\\quantum_model.py:146\u001b[0m, in \u001b[0;36mQuantumModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 146\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training:\n\u001b[0;32m    148\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_prediction(out)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\lambeq\\training\\numpy_model.py:192\u001b[0m, in \u001b[0;36mNumpyModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: \u001b[39mlist\u001b[39m[Diagram]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    175\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform default forward pass of a lambeq model.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[39m    In case of a different datapoint (e.g. list of tuple) or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m \n\u001b[0;32m    191\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_diagram_output(x)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\lambeq\\training\\numpy_model.py:158\u001b[0m, in \u001b[0;36mNumpyModel.get_diagram_output\u001b[1;34m(self, diagrams)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m \u001b[39mimport\u001b[39;00m numpy \u001b[39mas\u001b[39;00m jnp\n\u001b[0;32m    157\u001b[0m     lambdified_diagrams \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lambda(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m diagrams]\n\u001b[1;32m--> 158\u001b[0m     res: jnp\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39marray([diag_f(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\n\u001b[0;32m    159\u001b[0m                                   \u001b[39mfor\u001b[39;00m diag_f \u001b[39min\u001b[39;00m lambdified_diagrams])\n\u001b[0;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m    163\u001b[0m diagrams \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fast_subs(diagrams, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\lambeq\\training\\numpy_model.py:158\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m \u001b[39mimport\u001b[39;00m numpy \u001b[39mas\u001b[39;00m jnp\n\u001b[0;32m    157\u001b[0m     lambdified_diagrams \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lambda(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m diagrams]\n\u001b[1;32m--> 158\u001b[0m     res: jnp\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39marray([diag_f(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights)\n\u001b[0;32m    159\u001b[0m                                   \u001b[39mfor\u001b[39;00m diag_f \u001b[39min\u001b[39;00m lambdified_diagrams])\n\u001b[0;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m    163\u001b[0m diagrams \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fast_subs(diagrams, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\pjit.py:250\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39m@api_boundary\u001b[39m\n\u001b[0;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcache_miss\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 250\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr \u001b[39m=\u001b[39m _python_pjit_helper(\n\u001b[0;32m    251\u001b[0m       fun, infer_params_fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    252\u001b[0m   executable \u001b[39m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[0;32m    253\u001b[0m   fastpath_data \u001b[39m=\u001b[39m _get_fastpath_data(executable, out_tree, args_flat, out_flat)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\pjit.py:163\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[1;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   dispatch\u001b[39m.\u001b[39mcheck_arg(arg)\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m   out_flat \u001b[39m=\u001b[39m pjit_p\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs_flat, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m pxla\u001b[39m.\u001b[39mDeviceAssignmentMismatchError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m   fails, \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39margs\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\core.py:2677\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m   2673\u001b[0m axis_main \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m((axis_frame(a)\u001b[39m.\u001b[39mmain_trace \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m used_axis_names(\u001b[39mself\u001b[39m, params)),\n\u001b[0;32m   2674\u001b[0m                 default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m t: \u001b[39mgetattr\u001b[39m(t, \u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m   2675\u001b[0m top_trace \u001b[39m=\u001b[39m (top_trace \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m axis_main \u001b[39mor\u001b[39;00m axis_main\u001b[39m.\u001b[39mlevel \u001b[39m<\u001b[39m top_trace\u001b[39m.\u001b[39mlevel\n\u001b[0;32m   2676\u001b[0m              \u001b[39melse\u001b[39;00m axis_main\u001b[39m.\u001b[39mwith_cur_sublevel())\n\u001b[1;32m-> 2677\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(top_trace, args, params)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\core.py:383\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 383\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[0;32m    384\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\core.py:815\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[1;32m--> 815\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39mimpl(\u001b[39m*\u001b[39mtracers, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\pjit.py:1203\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[1;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[0;32m   1200\u001b[0m donated_argnums \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(donated_invars) \u001b[39mif\u001b[39;00m d]\n\u001b[0;32m   1201\u001b[0m has_explicit_sharding \u001b[39m=\u001b[39m _pjit_explicit_sharding(\n\u001b[0;32m   1202\u001b[0m     in_shardings, out_shardings, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1203\u001b[0m \u001b[39mreturn\u001b[39;00m xc\u001b[39m.\u001b[39;49m_xla\u001b[39m.\u001b[39;49mpjit(name, f, call_impl_cache_miss, [], [], donated_argnums,\n\u001b[0;32m   1204\u001b[0m                     _get_cpp_global_cache(has_explicit_sharding))(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\pjit.py:1187\u001b[0m, in \u001b[0;36m_pjit_call_impl.<locals>.call_impl_cache_miss\u001b[1;34m(*args_, **kwargs_)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_impl_cache_miss\u001b[39m(\u001b[39m*\u001b[39margs_, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_):\n\u001b[1;32m-> 1187\u001b[0m   out_flat, compiled \u001b[39m=\u001b[39m _pjit_call_impl_python(\n\u001b[0;32m   1188\u001b[0m       \u001b[39m*\u001b[39;49margs, jaxpr\u001b[39m=\u001b[39;49mjaxpr, in_shardings\u001b[39m=\u001b[39;49min_shardings,\n\u001b[0;32m   1189\u001b[0m       out_shardings\u001b[39m=\u001b[39;49mout_shardings, resource_env\u001b[39m=\u001b[39;49mresource_env,\n\u001b[0;32m   1190\u001b[0m       donated_invars\u001b[39m=\u001b[39;49mdonated_invars, name\u001b[39m=\u001b[39;49mname, keep_unused\u001b[39m=\u001b[39;49mkeep_unused,\n\u001b[0;32m   1191\u001b[0m       inline\u001b[39m=\u001b[39;49minline)\n\u001b[0;32m   1192\u001b[0m   fastpath_data \u001b[39m=\u001b[39m _get_fastpath_data(\n\u001b[0;32m   1193\u001b[0m       compiled, tree_structure(out_flat), args, out_flat)\n\u001b[0;32m   1194\u001b[0m   \u001b[39mreturn\u001b[39;00m out_flat, fastpath_data\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\pjit.py:1123\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[1;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[39mglobal\u001b[39;00m _most_recent_pjit_call_executable\n\u001b[0;32m   1116\u001b[0m in_shardings \u001b[39m=\u001b[39m _resolve_in_shardings(\n\u001b[0;32m   1117\u001b[0m     args, in_shardings, out_shardings,\n\u001b[0;32m   1118\u001b[0m     resource_env\u001b[39m.\u001b[39mphysical_mesh \u001b[39mif\u001b[39;00m resource_env \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   1120\u001b[0m compiled \u001b[39m=\u001b[39m _pjit_lower(\n\u001b[0;32m   1121\u001b[0m     jaxpr, in_shardings, out_shardings, resource_env,\n\u001b[0;32m   1122\u001b[0m     donated_invars, name, keep_unused, inline,\n\u001b[1;32m-> 1123\u001b[0m     always_lower\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, lowering_platform\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\u001b[39m.\u001b[39;49mcompile()\n\u001b[0;32m   1124\u001b[0m _most_recent_pjit_call_executable\u001b[39m.\u001b[39mweak_key_dict[jaxpr] \u001b[39m=\u001b[39m compiled\n\u001b[0;32m   1125\u001b[0m \u001b[39m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:2323\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[1;34m(self, compiler_options)\u001b[0m\n\u001b[0;32m   2320\u001b[0m   executable \u001b[39m=\u001b[39m MeshExecutable\u001b[39m.\u001b[39mfrom_trivial_jaxpr(\n\u001b[0;32m   2321\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile_args)\n\u001b[0;32m   2322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2323\u001b[0m   executable \u001b[39m=\u001b[39m UnloadedMeshExecutable\u001b[39m.\u001b[39mfrom_hlo(\n\u001b[0;32m   2324\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name,\n\u001b[0;32m   2325\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hlo,\n\u001b[0;32m   2326\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile_args,\n\u001b[0;32m   2327\u001b[0m       compiler_options\u001b[39m=\u001b[39mcompiler_options)\n\u001b[0;32m   2328\u001b[0m \u001b[39mif\u001b[39;00m compiler_options \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2329\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m executable\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:2645\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2642\u001b[0m       mesh \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mmesh  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m       \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 2645\u001b[0m xla_executable, compile_options \u001b[39m=\u001b[39m _cached_compilation(\n\u001b[0;32m   2646\u001b[0m     hlo, name, mesh, spmd_lowering,\n\u001b[0;32m   2647\u001b[0m     tuple_args, auto_spmd_lowering, allow_prop_to_outputs,\n\u001b[0;32m   2648\u001b[0m     \u001b[39mtuple\u001b[39;49m(host_callbacks), backend, da, pmap_nreps,\n\u001b[0;32m   2649\u001b[0m     compiler_options_keys, compiler_options_values)\n\u001b[0;32m   2651\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(backend, \u001b[39m\"\u001b[39m\u001b[39mcompile_replicated\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   2652\u001b[0m   semantics_in_shardings \u001b[39m=\u001b[39m SemanticallyEqualShardings(in_shardings)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:2555\u001b[0m, in \u001b[0;36m_cached_compilation\u001b[1;34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, _allow_propagation_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_keys, compiler_options_values)\u001b[0m\n\u001b[0;32m   2550\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m, compile_options\n\u001b[0;32m   2552\u001b[0m \u001b[39mwith\u001b[39;00m dispatch\u001b[39m.\u001b[39mlog_elapsed_time(\n\u001b[0;32m   2553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFinished XLA compilation of \u001b[39m\u001b[39m{fun_name}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{elapsed_time}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2554\u001b[0m     fun_name\u001b[39m=\u001b[39mname, event\u001b[39m=\u001b[39mdispatch\u001b[39m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[1;32m-> 2555\u001b[0m   xla_executable \u001b[39m=\u001b[39m dispatch\u001b[39m.\u001b[39;49mcompile_or_get_cached(\n\u001b[0;32m   2556\u001b[0m       backend, computation, dev, compile_options, host_callbacks)\n\u001b[0;32m   2557\u001b[0m \u001b[39mreturn\u001b[39;00m xla_executable, compile_options\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\dispatch.py:497\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[1;34m(backend, computation, devices, compile_options, host_callbacks)\u001b[0m\n\u001b[0;32m    493\u001b[0m use_compilation_cache \u001b[39m=\u001b[39m (compilation_cache\u001b[39m.\u001b[39mis_initialized() \u001b[39mand\u001b[39;00m\n\u001b[0;32m    494\u001b[0m                          backend\u001b[39m.\u001b[39mplatform \u001b[39min\u001b[39;00m supported_platforms)\n\u001b[0;32m    496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m use_compilation_cache:\n\u001b[1;32m--> 497\u001b[0m   \u001b[39mreturn\u001b[39;00m backend_compile(backend, computation, compile_options,\n\u001b[0;32m    498\u001b[0m                          host_callbacks)\n\u001b[0;32m    500\u001b[0m cache_key \u001b[39m=\u001b[39m compilation_cache\u001b[39m.\u001b[39mget_cache_key(\n\u001b[0;32m    501\u001b[0m     computation, devices, compile_options, backend)\n\u001b[0;32m    503\u001b[0m cached_executable \u001b[39m=\u001b[39m _cache_read(module_name, cache_key, compile_options,\n\u001b[0;32m    504\u001b[0m                                 backend)\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mc:\\Users\\Henry\\Desktop\\A\\quantum_env\\lib\\site-packages\\jax\\_src\\dispatch.py:465\u001b[0m, in \u001b[0;36mbackend_compile\u001b[1;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[0;32m    460\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m    461\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[0;32m    462\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'quantum_env (Python 3.10.7)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "\n",
    "ansatz_param_config = {\n",
    "    '1_1':{AtomicType.NOUN: 1, AtomicType.SENTENCE: 1},\n",
    "    '2_1':{AtomicType.NOUN: 2, AtomicType.SENTENCE: 1},\n",
    "    '1_2':{AtomicType.NOUN: 1, AtomicType.SENTENCE: 2},\n",
    "    '2_2':{AtomicType.NOUN: 2, AtomicType.SENTENCE: 2},\n",
    "    }\n",
    "\n",
    "optimizer_param_config = {\n",
    "    '0.01_0.01_'+str(0.01*EPOCHS): {'a': 0.01, 'c': 0.01, 'A':0.01*EPOCHS},\n",
    "    '0.01_0.1_'+str(0.01*EPOCHS): {'a': 0.01, 'c': 0.1, 'A':0.01*EPOCHS},\n",
    "    '0.01_1.0_'+str(0.01*EPOCHS): {'a': 0.01, 'c': 1.0, 'A':0.01*EPOCHS},\n",
    "    '0.1_0.01_'+str(0.01*EPOCHS): {'a': 0.1, 'c': 0.01, 'A':0.01*EPOCHS},\n",
    "    '0.1_0.1_'+str(0.01*EPOCHS): {'a': 0.1, 'c': 0.1, 'A':0.01*EPOCHS},\n",
    "    '0.1_1.0_'+str(0.01*EPOCHS): {'a': 0.1, 'c': 1.0, 'A':0.01*EPOCHS},\n",
    "    '1.0_0.01_'+str(0.01*EPOCHS): {'a': 1.0, 'c': 0.01, 'A':0.01*EPOCHS},\n",
    "    '1.0_0.1_'+str(0.01*EPOCHS): {'a': 1.0, 'c': 0.1, 'A':0.01*EPOCHS},\n",
    "    '1.0_1.0_'+str(0.01*EPOCHS): {'a': 1.0, 'c': 1.0, 'A':0.01*EPOCHS},\n",
    "    }\n",
    "\n",
    "layer_config = {\n",
    "    '1':1,\n",
    "    '2':2,\n",
    "    '3':3\n",
    "}\n",
    "\n",
    "ansatz_config = {\n",
    "        #'IQP': IQPAnsatz,\n",
    "        'Sim14': Sim14Ansatz,\n",
    "        'Sim15': Sim15Ansatz,\n",
    "    }\n",
    "\n",
    "loss_function_config = {\n",
    "        'mse': MSELoss(),\n",
    "    }\n",
    "\n",
    "optimizer_config = {\n",
    "        'spsa': SPSAOptimizer,\n",
    "    }\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "SEED = 42\n",
    "for ansatz_name, ansatz in ansatz_config.items():\n",
    "    for ansatz_param_name, ansatz_param in ansatz_param_config.items():\n",
    "        for layer_name, layer in layer_config.items():\n",
    "            for loss_name, loss_function in loss_function_config.items():\n",
    "                for optimizer_name, optimizer in optimizer_config.items():\n",
    "                    for o_param_name, o_param in optimizer_param_config.items():\n",
    "                        run_quantum_trainer('random', ansatz(ansatz_param, n_layers = layer), loss_function, optimizer, o_param, EPOCHS, BATCH_SIZE, SEED, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
